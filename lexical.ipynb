{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ci741ML1L5qV"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import sys\n",
        "\n",
        "RESERVED_WORDS_LIST = [\n",
        "    \"TextWindow\",\n",
        "    \"ElseIf\",\n",
        "    \"EndIf\",\n",
        "    \"EndWhile\",\n",
        "    \"EndFor\",\n",
        "    \"EndSub\",\n",
        "    \"Goto\",\n",
        "    \"If\",\n",
        "    \"Then\",\n",
        "    \"Else\",\n",
        "    \"While\",\n",
        "    \"For\",\n",
        "    \"Sub\",\n",
        "    \"And\",\n",
        "    \"Or\",\n",
        "    \"Array\",\n",
        "    \"To\",\n",
        "    \"Step\",\n",
        "    \"Stack\",\n",
        "    \"Program\",\n",
        "]\n",
        "\n",
        "\n",
        "SPECIAL_SYMBOLS_DICT = {\n",
        "    \"<>\": \"tkn_diff\",\n",
        "    \"<=\": \"tkn_leq\",\n",
        "    \">=\": \"tkn_geq\",\n",
        "}\n",
        "\n",
        "SYMBOLS_DICT = {\n",
        "    \"=\": \"tkn_equals\",\n",
        "    \".\": \"tkn_period\",\n",
        "    \",\": \"tkn_comma\",\n",
        "    \":\": \"tkn_colon\",\n",
        "    \"[\": \"tkn_left_brac\",\n",
        "    \"]\": \"tkn_right_brac\",\n",
        "    \"(\": \"tkn_left_paren\",\n",
        "    \")\": \"tkn_right_paren\",\n",
        "    \"+\": \"tkn_plus\",\n",
        "    \"-\": \"tkn_minus\",\n",
        "    \"*\": \"tkn_times\",\n",
        "    \"/\": \"tkn_div\",\n",
        "    \"<\": \"tkn_less\",\n",
        "    \">\": \"tkn_greater\",\n",
        "}\n",
        "\n",
        "\n",
        "NUMBER_REGEX_PATTERN = r\"^\\d+\\.?\\d*$\"\n",
        "\n",
        "BOOLEANS_REGEX_PATTERN = r'\"(true|false)\"'\n",
        "\n",
        "TXT_REGEX_PATTERN = r'\".*?\"'\n",
        "\n",
        "SPECIAL_SYMBOLS_REGEX_PATTERN = r\"(?:<=|>=|<>)\"\n",
        "\n",
        "SYMBOLS_REGEX_PATTERN = \"|\".join([re.escape(symbol[0]) for symbol in SYMBOLS_DICT])\n",
        "SYMBOLS_REGEX_PATTERN = r\"[\" + SYMBOLS_REGEX_PATTERN + r\"]\"\n",
        "\n",
        "ID_REGEX_PATTERN = r\"^[^\\W\\d_]\\w*$\"\n",
        "\n",
        "RESERVED_WORDS_REGEX_PATTERN = r\"\\b(?:\" + \"|\".join(RESERVED_WORDS_LIST) + r\")\\b\"\n",
        "\n",
        "TOKEN_LIST = [\n",
        "    (\"tkn_number\", re.compile(NUMBER_REGEX_PATTERN)),\n",
        "    (\"boolean\", re.compile(BOOLEANS_REGEX_PATTERN, re.IGNORECASE)),\n",
        "    (\"tkn_text\", re.compile(TXT_REGEX_PATTERN)),\n",
        "    (\"special_symbol\", re.compile(SPECIAL_SYMBOLS_REGEX_PATTERN)),\n",
        "    (\"symbol\", re.compile(SYMBOLS_REGEX_PATTERN)),\n",
        "    (\"reserved_word\", re.compile(RESERVED_WORDS_REGEX_PATTERN)),\n",
        "    (\"id\", re.compile(ID_REGEX_PATTERN)),\n",
        "]\n",
        "\n",
        "\n",
        "def classify_token(token, lex):\n",
        "    if token == \"special_symbol\":\n",
        "        return SPECIAL_SYMBOLS_DICT[lex]\n",
        "    if token == \"symbol\":\n",
        "        return SYMBOLS_DICT[lex]\n",
        "    if token == \"reserved_word\":\n",
        "        return lex\n",
        "    if token == \"boolean\":\n",
        "        new_string = lex[1:-1]\n",
        "        return new_string.capitalize()\n",
        "    return token\n",
        "\n",
        "\n",
        "def aggregate_lex(token, lex):\n",
        "    if token == \"tkn_text\":\n",
        "        new_string = lex[1:-1]\n",
        "        return new_string\n",
        "    return lex\n",
        "\n",
        "\n",
        "class Token:\n",
        "    def __init__(self, token, lex, row, column):\n",
        "        self.token = classify_token(token, lex)\n",
        "        self.lex = aggregate_lex(token, lex)\n",
        "        self.row = row\n",
        "        self.column = column\n",
        "        self.token_type = token\n",
        "\n",
        "    def __str__(self):\n",
        "        special_cases = [\"special_symbol\", \"symbol\", \"reserved_word\", \"boolean\"]\n",
        "        if self.token_type in special_cases:\n",
        "            return \"<{}, {}, {}>\".format(self.token, self.row, self.column)\n",
        "        return \"<{}, {}, {}, {}>\".format(self.token, self.lex, self.row, self.column)\n",
        "\n",
        "\n",
        "def lexical(user_input):\n",
        "    lines = user_input.split(\"\\n\")\n",
        "    abort_analysis = False\n",
        "    for i in range(len(lines)):\n",
        "        row = lines[i]\n",
        "        j = 0\n",
        "\n",
        "        while j < len(row):\n",
        "            match = None\n",
        "            # Ignore spaces\n",
        "            if row[j] == \" \":\n",
        "                j += 1\n",
        "                continue\n",
        "\n",
        "            # Jump line if a comment is found\n",
        "            if row[j] == \"'\":\n",
        "                break\n",
        "\n",
        "            line_end = len(row)\n",
        "            break_loop = False\n",
        "            while j <= line_end:\n",
        "                word = row[j:line_end]\n",
        "\n",
        "                for token_type, compiled_regex in TOKEN_LIST:\n",
        "                    match = compiled_regex.match(word)\n",
        "                    if match:\n",
        "                        token_value = match.group()\n",
        "                        token_end = match.end()\n",
        "                        current_token = Token(token_type, token_value, i + 1, j + 1)\n",
        "\n",
        "                        j += token_end\n",
        "\n",
        "                        print(current_token)\n",
        "                        break_loop = True\n",
        "                        break\n",
        "\n",
        "                if break_loop:\n",
        "                    break\n",
        "                line_end -= 1\n",
        "\n",
        "            if not match:\n",
        "                print(\">>> Lexical Error (Line: {}, Pos: {})\".format(i + 1, j + 1))\n",
        "                abort_analysis = True\n",
        "                break\n",
        "\n",
        "        if abort_analysis:\n",
        "            break\n",
        "\n",
        "\n",
        "test_code = sys.stdin.read()\n",
        "lexical(test_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joG1qcLxhosw"
      },
      "outputs": [],
      "source": [
        "test_case_1=\"\"\"TextWindow  If   Or   Array\n",
        "\n",
        "    Sub\n",
        "                  Else ElseIf\n",
        "For\n",
        "\n",
        "          EndWhile\n",
        "\"\"\"\n",
        "\n",
        "test_case_2= \"\"\"' This might not work\n",
        "  add a TextWindow if my Array\n",
        "\n",
        "      ' Lets see if this work\n",
        "         If myArray is good Else Textwindow\n",
        "         EndIf ' Finish ðŸ˜€\n",
        "\"\"\"\n",
        "\n",
        "test_case_3=\"\"\"infiniteLoop:\n",
        "\n",
        "a = 0\n",
        "\n",
        "For i = a To 5\n",
        "  TextWindow.Write(i)\n",
        "  TextWindow.WriteLine(\" its a number.\")\n",
        "EndFor\n",
        "\n",
        "Goto infiniteLoop\n",
        "\"\"\"\n",
        "\n",
        "test_case_4= \"\"\"my_Var1 = +05\n",
        "my_Var_2 = -3.330\"\"\"\n",
        "\n",
        "test_case_5=\"\"\"120.075.389\"\"\"\n",
        "\n",
        "test_case_6=\"\"\"If x >= 20 Then {\n",
        "  big = \"True\"\n",
        "}\n",
        "Else {\n",
        "  big = \"False\"\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "test_case_7=\"\"\"4.559not6==\"1\"_id7\"\"\"\n",
        "testcases = [\n",
        "    test_case_1,\n",
        "    test_case_2,\n",
        "    test_case_3,\n",
        "    test_case_4,\n",
        "    test_case_5,\n",
        "    test_case_6,\n",
        "    test_case_7\n",
        "]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
